# -*- coding: utf-8 -*-
"""AeroVision_AI_Powered_Air_Quality_Index_Prediction_and_Monitoring_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o_8etyyRWiEljelT7Alki57_i-8taYgC
"""



"""# Predicting Air Quality Using Machine Learning

This project aims to analyze air quality data in India to gain insights into pollution levels, their spatial and temporal variations, and potential contributing factors. By examining trends and patterns in air quality measurements, the project seeks to understand the impact of pollution on public health and the environment and inform strategies for pollution mitigation and environmental policy.

- We are going to take following approach/steps:-
1. Problem Definition
2. Data Definition
3. Data Exploration
4. Data Preprocessing
5. Feature Engineering
6. Model Selection
7. Model Training
8. Model Evaluation
9. Hyperparameter Tuning
10. Model Interpretation

Dataset Link: https://www.kaggle.com/datasets/rohanrao/air-quality-data-in-india


# 1. Problem Definition:-
This problem encompasses tasks such as data collection, preprocessing, exploratory data analysis, feature engineering, statistical analysis, machine learning modeling, and visualization. The ultimate goal is to leverage data-driven insights to address challenges related to air pollution and promote sustainable development and public well-being in India.


# 2. Key Features in Air Quality Data

- **City** : Where the pollution data was recorded.

  
  
- **Date** : When the measurement was taken.

  
- **PM2.5 & PM10** : Dust particles (tiny vs. bigger) that harm lungs.

  
- **NO, NO2, NOx** : Gases from vehicles/industries, cause smog & breathing issues.

   
- **NH3 (Ammonia)** : From fertilizers/livestock, forms harmful particles.

   
- **CO (Carbon Monoxide)** : From incomplete fuel burning, toxic at high levels.

  
- **SO2 (Sulfur Dioxide)** : From coal/oil burning, causes acid rain & breathing problems.

  
- **O3 (Ozone)** : Good in upper atmosphere, harmful near ground (smog).

  
- **Benzene, Toluene, Xylene** : Chemicals from exhaust/paints/smoke, harmful to health.

  
- **AQI (Air Quality Index)** : A score (0–500) showing overall air quality.

   
- **AQI Bucket** : Category of air quality (Good, Moderate, Poor, Severe, etc.).

  
- **AQI (Air Quality Index)** : The Air Quality Index is a standardized index used to communicate the quality of the air and associated health risks to the public. It is calculated based on the concentrations of various pollutants such as PM2.5, PM10, NO2, SO2, CO, and O3, and provides an overall assessment of air quality ranging from "Good" to "Severe". Discrete variable representing the Air Quality Index value, which is calculated based on the concentrations of various pollutants and categorized into predefined ranges. Typical range: 0 to 500.

  
- **AQI_Bucket** : Categorical variable representing the classification of AQI into predefined buckets (e.g., "Good", "Satisfactory", "Moderate", "Poor", "Very Poor", "Severe"), indicating the overall air quality level. Example values: "Good", "Satisfactory", "Moderate", "Poor", "Very Poor", "Severe".
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install shap
# %pip install lightgbm

# Commented out IPython magic to ensure Python compatibility.
import warnings
import pickle
import numpy as np
import pandas as pd
import seaborn as sns
import scipy.stats as stats
from scipy import interpolate
from matplotlib import pyplot as plt

pd.set_option('display.max_columns', None)
warnings.filterwarnings("ignore")
np.random.seed(0)
# %matplotlib inline

# Model Training & Evaluation
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error

# Preprocessing & Feature Engineering
from sklearn.preprocessing import LabelEncoder

# Model Interpretation
import shap

df = pd.read_csv('/city_aqi_day.csv', parse_dates = ['Date'], low_memory = False)
df.head(2)

df.info()

df.describe()

round(df.isna().sum()/len(df) * 100, 2)

"""**AQI Bucket category count**"""

aqi_bucket_percentages = (df['AQI_Bucket'].value_counts() / len(df)) * 100
plt.figure(figsize=(8, 8))
plt.pie(aqi_bucket_percentages, labels=aqi_bucket_percentages.index, autopct='%1.1f%%', startangle=140)
plt.title('Distribution of AQI Buckets')
plt.show()

df.groupby('AQI_Bucket').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

#AQI_Bucket with respect to cities
plt.figure(figsize=(12,6))
sns.histplot(data=df,x='City',hue='AQI_Bucket',palette='Dark2',multiple='stack',shrink=0.8)
plt.xticks(rotation=90)
plt.show()

"""**Handling Missing Values**"""

df.isnull().sum()

df.rename(columns={
    "PM2.5": "PM2_5",
    "PM10": "PM10",
    "NO": "NO",
    "NO2": "NO2",
    "NOx": "NOx",
    "NH3": "NH3",
    "CO": "CO",
    "SO2": "SO2",
    "O3": "O3",
    "Benzene": "Benzene",
    "Toluene": "Toluene",
    "Xylene": "Xylene",
    "AQI": "AQI",
    "AQI_Bucket": "AQI_Bucket",
    "City": "City",
    "Date": "Date"
}, inplace=True)

num_cols = df.select_dtypes(include=['float64','int64']).columns
df[num_cols] = df[num_cols].fillna(df[num_cols].median())

cat_cols = df.select_dtypes(include=['object']).columns
for col in cat_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

df.isnull().sum()

df.columns

# Select only numeric columns for correlation and plots
numeric_cols = ['PM2_5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3',
                'CO', 'SO2', 'O3', 'Benzene', 'Toluene',
                'Xylene', 'AQI']

# Correlation Matrix
plt.figure(figsize=(12,8))
corr = df[numeric_cols].corr()
sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Matrix of Air Quality Features")
plt.show()

# Box Plots (to check distribution & outliers)
plt.figure(figsize=(15,10))
for i, col in enumerate(numeric_cols, 1):
    plt.subplot(4,4,i)
    sns.boxplot(y=df[col], color="skyblue")
    plt.title(col)
plt.tight_layout()
plt.show()

# Pair Plot (relationships between features)
sns.pairplot(df[numeric_cols], diag_kind="kde", corner=True)
plt.suptitle("Pair Plot of Air Quality Features", y=1.02)
plt.show()

"""**Outlier Detect and Remove**"""

numeric_cols = ['PM2_5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3',
                'CO', 'SO2', 'O3', 'Benzene', 'Toluene',
                'Xylene', 'AQI']

# Detect and remove outliers using IQR
def remove_outliers(df, cols):
    for col in cols:
        Q1 = df[col].quantile(0.25)   # 25th percentile
        Q3 = df[col].quantile(0.75)   # 75th percentile
        IQR = Q3 - Q1                 # Interquartile range
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
    return df

df_clean = remove_outliers(df, numeric_cols)

# Check shape before and after
print("Original shape:", df.shape)
print("After removing outliers:", df_clean.shape)

# Quick check for remaining outliers
plt.figure(figsize=(15,10))
for i, col in enumerate(numeric_cols, 1):
    plt.subplot(4,4,i)
    sns.boxplot(y=df_clean[col], color="lightgreen")
    plt.title(col)
plt.tight_layout()
plt.show()

numeric_cols = ['PM2_5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3',
                'CO', 'SO2', 'O3', 'Benzene', 'Toluene',
                'Xylene', 'AQI']

# Function to calculate bounds (IQR method)
def get_bounds(df, cols):
    bounds = []
    for col in cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        bounds.append([col, round(lower_bound, 4), round(upper_bound, 4)])
    return pd.DataFrame(bounds, columns=["Column", "Lower Bound", "Upper Bound"])

# Generate bounds table
bounds_table = get_bounds(df_clean, numeric_cols)
print(bounds_table)

# Visualize bounds with boxplots
plt.figure(figsize=(15,10))
for i, col in enumerate(numeric_cols, 1):
    plt.subplot(4,4,i)
    sns.boxplot(y=df_clean[col], color="lightblue")
    plt.axhline(bounds_table.loc[bounds_table['Column']==col, 'Lower Bound'].values[0],
                color='red', linestyle='--', label='Lower Bound')
    plt.axhline(bounds_table.loc[bounds_table['Column']==col, 'Upper Bound'].values[0],
                color='green', linestyle='--', label='Upper Bound')
    plt.title(col)
    plt.legend()
plt.tight_layout()
plt.show()

numeric_cols = ['PM2_5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3',
                'CO', 'SO2', 'O3', 'Benzene', 'Toluene',
                'Xylene', 'AQI']

# Density plots for each pollutant
plt.figure(figsize=(15,12))
for i, col in enumerate(numeric_cols, 1):
    plt.subplot(4,4,i)
    sns.kdeplot(df_clean[col], color="red", shade=True)
    plt.title(f"Density Plot of {col}")
    plt.xlabel(col)
    plt.ylabel("Density")
plt.tight_layout()
plt.show()

"""**Feature Engineering**

# Feature Engineering

1. Feature Encode
2. Train and Test Split
3. Rolling Average (Feature Creation)
4. Feature Scaling

Steps followed:
1. First encode the city
2. Split the encoded dataframe into train and test dataframes
2. Calculate the rolling average based on 7 day window with minimum window size of 1.
3. Drop the city and aqi_rw_avg
4. We can scale or leave the data as it is on demand
"""

# Encode City
if 'City' in df.columns:
    le_city = LabelEncoder()
    df['City'] = le_city.fit_transform(df['City'])

# Encode AQI_Bucket
if 'AQI_Bucket' in df.columns:
    le_bucket = LabelEncoder()
    df['AQI_Bucket'] = le_bucket.fit_transform(df['AQI_Bucket'])

# Rolling average for AQI
df['AQI_rw_avg'] = df['AQI'].rolling(window=7, min_periods=1).mean()

# Drop redundant columns
df = df.drop(['AQI_rw_avg'], axis=1)

# Scale numeric features
scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

# Train-Test Split
X = df_clean.drop(['AQI_Bucket'], axis=1)   # features
y = df_clean['AQI_Bucket']                  # target

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Rolling Avg.
df_clean['AQI_rw_avg'] = df_clean['AQI'].rolling(window=7, min_periods=1).mean()

# Feature Scaling
scaler = StandardScaler()
num_cols = ['PM2_5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3',
            'CO', 'SO2', 'O3', 'Benzene', 'Toluene',
            'Xylene', 'AQI']

df_clean[num_cols] = scaler.fit_transform(df_clean[num_cols])

# Correlation plot after feature engineering
plt.figure(figsize=(12,8))
sns.heatmap(df_clean[num_cols].corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Matrix After Feature Engineering")
plt.show()

"""**Model Training and Evaluation**"""

X = df.drop(['AQI_Bucket'], axis=1)   # features
y = df['AQI']                         # target

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

df.dtypes

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Encode City if present
if 'City' in df.columns:
    le_city = LabelEncoder()
    df['City'] = le_city.fit_transform(df['City'])

# Encode AQI_Bucket if present
if 'AQI_Bucket' in df.columns:
    le_bucket = LabelEncoder()
    df['AQI_Bucket'] = le_bucket.fit_transform(df['AQI_Bucket'])

# Rolling average for AQI
df['AQI_rw_avg'] = df['AQI'].rolling(window=7, min_periods=1).mean()

# Drop redundant/non-numeric columns
drop_cols = ['AQI_rw_avg']
if 'Date' in df.columns:   # ✅ Drop Date to avoid dtype error
    drop_cols.append('Date')
df = df.drop(drop_cols, axis=1)

# Scale numeric features
scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

# 5. Train-Test Split
X = df.drop(['AQI_Bucket'], axis=1)   # features
y = df['AQI']                         # target

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Random Forest
rf_model = RandomForestRegressor(n_estimators=200, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)

# XGBoost
xgb_model = XGBRegressor(n_estimators=200, learning_rate=0.1, random_state=42)
xgb_model.fit(X_train, y_train)
xgb_preds = xgb_model.predict(X_test)

# 7. Evaluation
rf_r2 = r2_score(y_test, rf_preds)
rf_rmse = np.sqrt(mean_squared_error(y_test, rf_preds))

xgb_r2 = r2_score(y_test, xgb_preds)
xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_preds))

results = pd.DataFrame({
    "Model": ["Random Forest", "XGBoost"],
    "R2 Score": [rf_r2, xgb_r2],
    "RMSE": [rf_rmse, xgb_rmse]
})
print(results)

# 8. Visual Comparison
plt.figure(figsize=(10,5))
sns.barplot(x="Model", y="R2 Score", data=results, palette="viridis")
plt.title("Model Comparison (R2 Score)")
plt.show()

plt.figure(figsize=(10,5))
sns.barplot(x="Model", y="RMSE", data=results, palette="magma")
plt.title("Model Comparison (RMSE)")
plt.show()

"""**Model Interpretation**"""

# 1. SHAP Explainer for Random Forest
explainer_rf = shap.TreeExplainer(rf_model)
shap_values_rf = explainer_rf.shap_values(X_test)
shap.summary_plot(shap_values_rf, X_test, plot_type="bar")


# 2. SHAP Explainer for XGBoost
explainer_xgb = shap.TreeExplainer(xgb_model)
shap_values_xgb = explainer_xgb.shap_values(X_test)
shap.summary_plot(shap_values_xgb, X_test, plot_type="bar")

# 3. KDE Plots for SHAP values
shap_rf_df = pd.DataFrame(shap_values_rf, columns=X_test.columns)
shap_xgb_df = pd.DataFrame(shap_values_xgb, columns=X_test.columns)

plt.figure(figsize=(15,12))
for i, col in enumerate(X_test.columns[:12], 1):  # limit to first 12 features for clarity
    plt.subplot(4,3,i)
    sns.kdeplot(shap_rf_df[col], color="blue", shade=True, label="RF SHAP")
    sns.kdeplot(shap_xgb_df[col], color="red", shade=True, label="XGB SHAP")
    plt.title(f"SHAP KDE: {col}")
    plt.legend()
plt.tight_layout()
plt.show()

"""**Model Interpretation**

 Global Importance (Bar Chart)
- PM2.5 is the most critical feature driving AQI predictions.
- CO, SO₂, PM10, NO₂ also have strong influence.
- O₃, Benzene, Toluene contribute less overall.
- City encoding matters, but pollutants dominate.

 SHAP KDE Plots
- NH₃, CO, SO₂ → show wider SHAP distributions, meaning their impact varies a lot across samples.
- O₃, Benzene, Toluene → SHAP values mostly near zero, smaller effect.
- Random Forest vs XGBoost → both agree on feature importance, but XGBoost shows sharper, more confident distributions.

 Takeaway
- PM2.5 is the strongest predictor of AQI.
- Gas pollutants (CO, SO₂, NO₂) are key secondary drivers.
- Both models highlight the same pollutants, confirming consistency.



"""

